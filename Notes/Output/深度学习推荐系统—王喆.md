### 深度学习推荐系统 —— 王喆

#### chpt1 互联网的增长引擎——推荐系统

概念：

* UGC(User Generated Content)，典型如Youtube、Tiktok
* CVR (Conversion Rate)、观看时长(Youtube Recommendations)

推荐系统架构：数据与模型

* 物品信息、用户信息、场景信息
* 数据离线批处理、实时流处理



#### chpt2 前深度学习时代——推荐系统的进化之路

1.演化关系图  p13

2.协同过滤(CF)

UserCF
* 用户相似度计算：余弦相似度/皮尔逊相关系数/引入物品平均分
* 最终结果的排序：按相似度加权
* 特点：社交特性更强
* 缺点：
  * 用户太多，在线存储系统存不下矩阵。 
  * 不适用于正反馈获取困难的应用场景（酒店预定、大件商品购买），用户历史数据向量稀疏

协同过滤的缺点
* 推荐系统的头部效应较明显，处理稀疏向量的能力弱 => MF用更稠密的隐向量表示用户和物品
* 无法引入场景信息和更精细的用户/物品信息 => LR模型、机器学习模型



3.矩阵分解(MF)

* 用户和物品的隐向量通过分解协同过滤生成的共现矩阵得到
* 矩阵分解的方法：特征值分解（方阵，不适用）；SVD（计算量大、要求稠密）；梯度下降法
* 矩阵分解可加入偏差向量
* 优点：
  * 泛化能力强
  * 空间复杂度低
  * 更好的扩展性和灵活性
* 缺点
  * 同样不方便加入场景信息和更精细的用户/物品信息



4.逻辑回归 (LR)

将推荐问题转换为一个CTR预估问题

流行原因：1）数学含义上的支撑 2）可解释性强 3）工程化的需要



5.从FM到FFM——自动特征交叉的解决方案

* Poly2——特征交叉的开始
* FM模型——隐向量特征交叉 (2012-2014)
  * 参数减少到n*k，减小训练开销，增大收敛可能
* FFM模型——引入特征域的概念 (2015)



6.GBDT+LR——特征工程模型化的开端

组合模型，一定程度上解决特征交叉的问题

优点：e2e特征工程模型化

缺点：容易过拟合；丢失大量特征的数值信息



7.LS-PLM —— alibaba曾经的主流推荐模型

也称为MLR(Mix Logistic Regression)，在逻辑回归的基础上加入聚类的思想，其灵感来自对广告推荐领域样本特点的观察

* 超参数：分片数m，阿里的经验值为12

优势：

* 端到端的非线性学习能力
* 模型稀疏性强



引申：

* L1范数比L2范数更容易产生稀疏解，因为加入正则化项的损失函数最小值更容易在参数空间的顶点处取得，对应稀疏参数



#### chpt3 浪潮之巅——深度学习在推荐系统中的应用

1.演化关系图：p51

2.[AutoRec](https://zhuanlan.zhihu.com/p/159087297) —— 单隐层神经网络推荐模型

结合了auto-encoder和协同过滤的思想，本质上是训练auto-encoder保存推荐系统的泛化信息，输入一个“不完整”的、“真实”的评分条目列表，得到对应这个条目列表的相似条目列表

* I-AutoRec, U-AutoRec

3.Deep Crossing模型 —— 经典的深度学习架构

* 如何解决稀疏特征向量稠密化的问题？
  * 除数值类特征，进入Embedding层
* 如何解决特征自动交叉的问题？
  * 无人工特征交叉，全部交给模型，残差神经网络加强提取非线性特征和组合特征信息的能力
* 如何在输出层中达成问题设定的优化目标？
  * 最后一层逻辑回归

4.NeuralCF模型——CF与深度学习的结合

* 用神经网络替代CF最后一层打分的点积操作
* NeuralCF混合模型：concat原始NeuralCF模型的输出和以element-wise product为互操作的广义矩阵分解模型
* 局限性和CF一致：没引入其他类型的特征、具体的互操作有待探索

5.PNN模型——加强特征交叉能力

Product层：线性操作 + 乘积操作
* 乘积操作 = 内积(IPNN)/外积(OPNN)
* 叠加外积互操作矩阵：本质上是让所有embedding通过一个平均池化层后，再进行外积互操作
  * [embedding的意义](https://www.zhihu.com/question/374835153/answer/1042845667)

6.Wide&Deep模型——记忆能力和泛化能力的综合

具体参考[MLSys.md](https://github.com/huangrt01/CS-Notes/blob/master/Notes/Output/MLSys.md)

7.




#### chpt6 深度学习推荐系统的工程实现

1 推荐系统的数据流

四种架构：批处理、流计算、Lambda、Kappa

2 Spark MLlib

3 Parameter Server

* Spark MLlib: 同步阻断式
* Parameter Server: 异步非阻断式

两者区别在于模型参数的分发是否同步

6 工程与理论之间的均衡

* end2end：强调模型一致性的收益
* two stages：强调模型实时性的收益









Graph Service: 

* 基于Euler改造
  * 支持全图节点遍历，支持按时间戳采样

* 高性能采样
  * 节点生成前缀和，二分查找随机数
  * 全局点采样：shard有权（shard上所有节点的权重），shard内再次按权
* Graph Embedding on GPU: sample和worker分离
* GE应用
  * 预训练：利用uid与author间的finish关系，构造双向异构图。边权重用finish视频数量，点权重用finish视频总数。
    * 不用gid而用author是为了减小图结构随时间的变化
    * 正负例构造：正例是user及其finish的节点，负例随机采样
  * end2end training
    * 利用uid和cid之间的click关系，边权重是click次数，点权重是click总数
    * 采样：有放回按权采样
    * 优点：训练目标和LTR任务一致
    * 缺点：1.全局图的拟合能力不如业务图 2.end2end结构更自由，可以用node2vec等
  * Finetune BERT/Resnet
    * cid和cid的co-click，边权重用交并比，点权重用click总数，点特征用广告id类泛化特征